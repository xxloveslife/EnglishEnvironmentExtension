import json
from typing import Optional
import aiohttp
import asyncio
import os
from openai import OpenAI

from config.env import AppConfig


class LLMClient:
    def __init__(self, api_key: str, base_url:str = "https://api.llvm.org/"):
        # åˆå§‹åŒ–
        # Args:  key ,  url
        self.api_key = api_key or os.getenv("DASHSCOPE_API_KEY") or AppConfig.dashscope_api_key
        if not self.api_key:
            raise ValueError("Please set DASHSCOPE_API_KEY environment variable")
        self.base_url = base_url.rstrip('/')
        self.session: Optional[aiohttp.ClientSession] = None
        self.client = OpenAI(
            # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key="sk-xxx"
            # api_key=os.getenv("DASHSCOPE_API_KEY"),
            # api_key='sk-050494a7fbff4799aa4af58f9ec627a1',
            api_key=self.api_key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",

        )

    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()




    async def translate_batch(self,texts, user_level):

        my_prompts = f"""
            ä½ æ˜¯ä¸€ä¸ªä¸­è‹±æ··åˆå­¦ä¹ åŠ©æ‰‹ï¼Œéœ€è¦æ ¹æ®ç”¨æˆ·çš„è‹±è¯­æ°´å¹³ï¼Œå°†ä¸­æ–‡æ–‡æœ¬ä¸­çš„éƒ¨åˆ†è¯æ±‡æ›¿æ¢ä¸ºåˆé€‚çš„è‹±æ–‡å•è¯ï¼Œå¸®åŠ©ç”¨æˆ·åœ¨é˜…è¯»ä¸­è‡ªç„¶ä¹ å¾—æ–°è¯æ±‡ã€‚
            
            **å¤„ç†è§„åˆ™ï¼š**
            1. **ç”¨æˆ·æ°´å¹³åˆ¤æ–­**ï¼šç”¨æˆ·å½“å‰è‹±è¯­ç­‰çº§ä¸ºã€{user_level}ã€‘ã€‚è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†é€‰æ‹©æ›¿æ¢è¯æ±‡ï¼š
               - åˆçº§ï¼šæ›¿æ¢æœ€åŸºç¡€çš„æ—¥å¸¸è¯æ±‡ï¼ˆå¦‚åè¯ã€ç®€å•åŠ¨è¯ï¼‰
               - ä¸­çº§ï¼šæ›¿æ¢å¸¸è§å½¢å®¹è¯ã€çŸ­è¯­åŠ¨è¯ã€å¸¸ç”¨è¡¨è¾¾
               - é«˜çº§ï¼šæ›¿æ¢è¾ƒä¸“ä¸šçš„æœ¯è¯­ã€å­¦æœ¯è¯æ±‡ã€æƒ¯ç”¨è¯­
            2. **æ›¿æ¢åŸåˆ™**ï¼š
               - åªæ›¿æ¢èƒ½ä¿ƒè¿›å­¦ä¹ çš„â€œå¯ä¹ å¾—è¯æ±‡â€ï¼ˆç¬¦åˆi+1è¾“å…¥å‡è¯´ï¼‰
               - ä¿æŒåŸå¥ç»“æ„å’Œè¯­æ³•å®Œæ•´
               - ä¸æ›¿æ¢ä¸“æœ‰åè¯ã€äººåã€å“ç‰Œå
               - ä¸æ›¿æ¢æ•°å­—ã€æ—¥æœŸã€åº¦é‡å•ä½
               - ä¸æ”¹å˜UIå…ƒç´ ã€æŒ‰é’®åç§°ã€ç•Œé¢æ–‡æ¡ˆ
            3. **è¾“å‡ºæ ¼å¼**ï¼šè¿”å›ä¸è¾“å…¥å®Œå…¨ç›¸åŒçš„åˆ—è¡¨ç»“æ„ï¼Œåªä¿®æ”¹éœ€è¦æ›¿æ¢çš„éƒ¨åˆ†
            4. **ç‰¹æ®Šå¤„ç†**ï¼š
               - äº’åŠ¨ç±»æ–‡æœ¬ï¼ˆå¦‚â€œèµåŒ 117â€ã€â€œæ”¶è—â€ï¼‰ä¸ç¿»è¯‘
               - æ ‡ç­¾ç±»æ–‡æœ¬ï¼ˆå¦‚â€œå…³æ³¨â€ã€â€œçƒ­æ¦œâ€ï¼‰ä¸ç¿»è¯‘
               - é•¿æ®µè½åªæ›¿æ¢3-5ä¸ªå…³é”®è¯ï¼Œé¿å…è¿‡åº¦æ›¿æ¢
               - ä¿æŒåŸæ–‡æƒ…æ„Ÿè‰²å½©å’Œå£è¯­é£æ ¼
            
            **ç¤ºä¾‹å‚è€ƒï¼š**
            ç”¨æˆ·ç­‰çº§ï¼šåˆçº§
            è¾“å…¥ï¼š["æˆ‘å–œæ¬¢è¯»ä¹¦", "ä»Šå¤©å¤©æ°”çœŸå¥½"]
            è¾“å‡ºï¼š["æˆ‘å–œæ¬¢è¯»books", "ä»Šå¤©weatherçœŸå¥½"]
            
            ç”¨æˆ·ç­‰çº§ï¼šä¸­çº§
            è¾“å…¥ï¼š["ä»–ç»å¸¸ç†¬å¤œå·¥ä½œ"]
            è¾“å‡ºï¼š["ä»–ç»å¸¸stay up lateå·¥ä½œ"]
            
            ç”¨æˆ·ç­‰çº§ï¼šé«˜çº§
            è¾“å…¥ï¼š["è¿™ä¸ªè§‚ç‚¹å¾ˆæœ‰æ´å¯ŸåŠ›"]
            è¾“å‡ºï¼š["è¿™ä¸ªperspectiveå¾ˆæœ‰insight"]
            
            **å½“å‰ä»»åŠ¡ï¼š**
            ç”¨æˆ·ç­‰çº§ï¼š{user_level}
            
            
            è¯·è¿”å›å¤„ç†åçš„å®Œæ•´åˆ—è¡¨ï¼Œä¿æŒåŸæœ‰é¡ºåºå’Œé•¿åº¦ã€‚åªè¾“å‡ºJSONæ ¼å¼çš„åˆ—è¡¨ï¼Œä¸è¦é¢å¤–è§£é‡Šã€‚
            """

        completion = self.client.chat.completions.create(
            # æ¨¡å‹åˆ—è¡¨ï¼šhttps://help.aliyun.com/zh/model-studio/getting-started/models
            model="qwen-plus",
            messages=[ # type: ignore
                {"role": "system", "content": my_prompts},
                {"role": "user", "content":  json.dumps(texts, ensure_ascii=False)},
            ]
        )
        translated_texts = json.loads(completion.choices[0].message.content)
        # print(completion.model_dump_json())
        return translated_texts


# æµ‹è¯•ä»£ç  - ä½¿ç”¨ async with
async def test_with_context():
    print("ğŸš€ ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨æµ‹è¯•...")

    # ä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    async with LLMClient(api_key="dummy_key") as client:
        await client.translate_batch(
            texts=["æµ‹è¯•æ–‡æœ¬1", "æµ‹è¯•æ–‡æœ¬2"],
            user_level="é«˜çº§"
        )

    print("âœ… æµ‹è¯•å®Œæˆï¼ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¼šè‡ªåŠ¨å…³é—­session")


# æµ‹è¯•
if __name__ == "__main__":
    asyncio.run(test_with_context())